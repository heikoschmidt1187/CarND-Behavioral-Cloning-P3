1 - general processing like in the videos
  - first training data with one round
  - car drives in right circles

2 - added pixel normalization Lambda
  - decreased epochs to 5 for a better loss
  - loss: 0.4239

3 - implemented LeNet from traffic sign classifier project in Keras and adapted to
    the use as a learning network for automomous driving
  - increased epochs to 10, it's too much but validation loss is at 0.0033
  --> changed back to 4 --> val_loss 0.0011

4 - Augmentation of data by flipping, still bad on driving despite good loss ???

5 - Implemented usage of left and right image + steering measurment correction
    factor of 0.2
  - val_loss = 0.003
  - better, not one full round, but first turns are taken slooowly but right :-D

6 - cropping not important parts from the image to eliminate sky, trees, mountains, car hood
  - val_loss 0.0229....what!?

7 - implemented NVIDIA CNN for automomous driving
  - 10 epochs
  - val_loss 0.0075, loss decreasing, val loss stagnation --> overfitting
  - first full round!!!! :-D

8 - two more rounds left, two round right, some revover training data left
  - val_loss 0.0419, loss 0.0037 -- massively overfitting
  - baaad driving

9 - added dropout layers with 0.5 after each FC layers
  - val_loss 0.03x --> loss 0.01...no good driving

10 - fixed bug...

2019-04-13 10:50:07.876727: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.1 locally
174/174 [==============================] - 90s 515ms/step - loss: 0.0480 - acc: 0.1078 - val_loss: 0.0357 - val_acc: 0.1139
Epoch 2/30
174/174 [==============================] - 88s 505ms/step - loss: 0.0408 - acc: 0.1086 - val_loss: 0.0353 - val_acc: 0.1139
Epoch 3/30
174/174 [==============================] - 88s 507ms/step - loss: 0.0384 - acc: 0.1082 - val_loss: 0.0340 - val_acc: 0.1138
Epoch 4/30
174/174 [==============================] - 88s 507ms/step - loss: 0.0378 - acc: 0.1082 - val_loss: 0.0329 - val_acc: 0.1139
Epoch 5/30
174/174 [==============================] - 89s 509ms/step - loss: 0.0369 - acc: 0.1090 - val_loss: 0.0337 - val_acc: 0.1139
Epoch 6/30
174/174 [==============================] - 88s 508ms/step - loss: 0.0370 - acc: 0.1082 - val_loss: 0.0335 - val_acc: 0.1139
Epoch 7/30
174/174 [==============================] - 88s 508ms/step - loss: 0.0363 - acc: 0.1077 - val_loss: 0.0324 - val_acc: 0.1139
Epoch 8/30
174/174 [==============================] - 88s 503ms/step - loss: 0.0353 - acc: 0.1086 - val_loss: 0.0321 - val_acc: 0.1139
Epoch 9/30
174/174 [==============================] - 88s 505ms/step - loss: 0.0347 - acc: 0.1086 - val_loss: 0.0326 - val_acc: 0.1138
Epoch 10/30
174/174 [==============================] - 89s 510ms/step - loss: 0.0347 - acc: 0.1078 - val_loss: 0.0319 - val_acc: 0.1139
Epoch 11/30
174/174 [==============================] - 87s 503ms/step - loss: 0.0343 - acc: 0.1086 - val_loss: 0.0317 - val_acc: 0.1139
Epoch 12/30
174/174 [==============================] - 89s 509ms/step - loss: 0.0340 - acc: 0.1082 - val_loss: 0.0312 - val_acc: 0.1139
Epoch 13/30
174/174 [==============================] - 89s 509ms/step - loss: 0.0336 - acc: 0.1083 - val_loss: 0.0311 - val_acc: 0.1139
Epoch 14/30
174/174 [==============================] - 88s 505ms/step - loss: 0.0331 - acc: 0.1086 - val_loss: 0.0313 - val_acc: 0.1139
Epoch 15/30
174/174 [==============================] - 89s 510ms/step - loss: 0.0332 - acc: 0.1082 - val_loss: 0.0308 - val_acc: 0.1139
Epoch 16/30
174/174 [==============================] - 89s 510ms/step - loss: 0.0331 - acc: 0.1078 - val_loss: 0.0304 - val_acc: 0.1139
Epoch 17/30
174/174 [==============================] - 88s 509ms/step - loss: 0.0328 - acc: 0.1087 - val_loss: 0.0303 - val_acc: 0.1139
Epoch 18/30
174/174 [==============================] - 88s 506ms/step - loss: 0.0323 - acc: 0.1087 - val_loss: 0.0309 - val_acc: 0.1139
Epoch 19/30
174/174 [==============================] - 89s 509ms/step - loss: 0.0325 - acc: 0.1083 - val_loss: 0.0307 - val_acc: 0.1139
Epoch 20/30
174/174 [==============================] - 88s 506ms/step - loss: 0.0318 - acc: 0.1082 - val_loss: 0.0297 - val_acc: 0.1139
Epoch 21/30
174/174 [==============================] - 88s 506ms/step - loss: 0.0312 - acc: 0.1078 - val_loss: 0.0302 - val_acc: 0.1139
Epoch 22/30
174/174 [==============================] - 89s 511ms/step - loss: 0.0310 - acc: 0.1078 - val_loss: 0.0305 - val_acc: 0.1139
Epoch 23/30
174/174 [==============================] - 89s 511ms/step - loss: 0.0304 - acc: 0.1083 - val_loss: 0.0303 - val_acc: 0.1139
Epoch 24/30
174/174 [==============================] - 88s 508ms/step - loss: 0.0306 - acc: 0.1079 - val_loss: 0.0295 - val_acc: 0.1139
Epoch 25/30
174/174 [==============================] - 89s 512ms/step - loss: 0.0299 - acc: 0.1083 - val_loss: 0.0293 - val_acc: 0.1139
Epoch 26/30
174/174 [==============================] - 92s 530ms/step - loss: 0.0294 - acc: 0.1092 - val_loss: 0.0285 - val_acc: 0.1139
Epoch 27/30
174/174 [==============================] - 103s 590ms/step - loss: 0.0293 - acc: 0.1083 - val_loss: 0.0287 - val_acc: 0.1139
Epoch 28/30
174/174 [==============================] - 102s 586ms/step - loss: 0.0291 - acc: 0.1083 - val_loss: 0.0284 - val_acc: 0.1139
Epoch 29/30
174/174 [==============================] - 103s 589ms/step - loss: 0.0287 - acc: 0.1083 - val_loss: 0.0282 - val_acc: 0.1139
Epoch 30/30
174/174 [==============================] - 109s 628ms/step - loss: 0.0285 - acc: 0.1088 - val_loss: 0.0292 - val_acc: 0.1139

----> 1 time out of road,

Maybe good version:
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
lambda_1 (Lambda)            (None, 160, 320, 3)       0
_________________________________________________________________
cropping2d_1 (Cropping2D)    (None, 65, 320, 3)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 31, 158, 24)       1824
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 14, 77, 36)        21636
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 5, 37, 48)         43248
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 3, 35, 64)         27712
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 1, 33, 64)         36928
_________________________________________________________________
flatten_1 (Flatten)          (None, 2112)              0
_________________________________________________________________
dense_1 (Dense)              (None, 100)               211300
_________________________________________________________________
dropout_1 (Dropout)          (None, 100)               0
_________________________________________________________________
dense_2 (Dense)              (None, 50)                5050
_________________________________________________________________
dense_3 (Dense)              (None, 10)                510
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 11
=================================================================
Total params: 348,219
Trainable params: 348,219
Non-trainable params: 0


2019-04-13 18:43:24.872276: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.1 locally
238/238 [==============================] - 126s 527ms/step - loss: 0.0282 - acc: 0.0497 - val_loss: 0.0227 - val_acc: 0.0523
Epoch 2/10
238/238 [==============================] - 123s 515ms/step - loss: 0.0224 - acc: 0.0497 - val_loss: 0.0212 - val_acc: 0.0523
Epoch 3/10
238/238 [==============================] - 129s 540ms/step - loss: 0.0206 - acc: 0.0497 - val_loss: 0.0195 - val_acc: 0.0523
Epoch 4/10
238/238 [==============================] - 217s 910ms/step - loss: 0.0191 - acc: 0.0497 - val_loss: 0.0182 - val_acc: 0.0523
Epoch 5/10
238/238 [==============================] - 185s 779ms/step - loss: 0.0181 - acc: 0.0497 - val_loss: 0.0179 - val_acc: 0.0523
Epoch 6/10
238/238 [==============================] - 122s 513ms/step - loss: 0.0172 - acc: 0.0497 - val_loss: 0.0163 - val_acc: 0.0523
Epoch 7/10
238/238 [==============================] - 124s 521ms/step - loss: 0.0167 - acc: 0.0497 - val_loss: 0.0159 - val_acc: 0.0523
Epoch 8/10
238/238 [==============================] - 125s 525ms/step - loss: 0.0164 - acc: 0.0497 - val_loss: 0.0156 - val_acc: 0.0523
Epoch 9/10
238/238 [==============================] - 126s 532ms/step - loss: 0.0159 - acc: 0.0497 - val_loss: 0.0149 - val_acc: 0.0523
Epoch 10/10
238/238 [==============================] - 129s 541ms/step - loss: 0.0155 - acc: 0.0496 - val_loss: 0.0150 - val_acc: 0.0523
Epoch 00010: early stopping


_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
lambda_1 (Lambda)            (None, 160, 320, 3)       0
_________________________________________________________________
cropping2d_1 (Cropping2D)    (None, 65, 320, 3)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 31, 158, 24)       1824
_________________________________________________________________
batch_normalization_1 (Batch (None, 31, 158, 24)       96
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 14, 77, 36)        21636
_________________________________________________________________
batch_normalization_2 (Batch (None, 14, 77, 36)        144
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 5, 37, 48)         43248
_________________________________________________________________
batch_normalization_3 (Batch (None, 5, 37, 48)         192
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 3, 35, 64)         27712
_________________________________________________________________
batch_normalization_4 (Batch (None, 3, 35, 64)         256
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 1, 33, 64)         36928
_________________________________________________________________
batch_normalization_5 (Batch (None, 1, 33, 64)         256
_________________________________________________________________
flatten_1 (Flatten)          (None, 2112)              0
_________________________________________________________________
dense_1 (Dense)              (None, 100)               211300
_________________________________________________________________
dropout_1 (Dropout)          (None, 100)               0
_________________________________________________________________
dense_2 (Dense)              (None, 50)                5050
_________________________________________________________________
dense_3 (Dense)              (None, 10)                510
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 11
=================================================================
Total params: 349,163
Trainable params: 348,691
Non-trainable params: 472


238/238 [==============================] - 149s 625ms/step - loss: 0.2770 - acc: 0.0335 - val_loss: 0.0394 - val_acc: 0.0506
Epoch 2/10
238/238 [==============================] - 148s 621ms/step - loss: 0.0580 - acc: 0.0490 - val_loss: 0.0282 - val_acc: 0.0510
Epoch 3/10
238/238 [==============================] - 151s 634ms/step - loss: 0.0387 - acc: 0.0498 - val_loss: 0.0247 - val_acc: 0.0510
Epoch 4/10
238/238 [==============================] - 151s 635ms/step - loss: 0.0319 - acc: 0.0499 - val_loss: 0.0207 - val_acc: 0.0510
Epoch 5/10
238/238 [==============================] - 154s 647ms/step - loss: 0.0284 - acc: 0.0500 - val_loss: 0.0195 - val_acc: 0.0510
Epoch 6/10
238/238 [==============================] - 155s 652ms/step - loss: 0.0264 - acc: 0.0500 - val_loss: 0.0192 - val_acc: 0.0510
Epoch 7/10
238/238 [==============================] - 164s 691ms/step - loss: 0.0245 - acc: 0.0500 - val_loss: 0.0186 - val_acc: 0.0510
Epoch 8/10
238/238 [==============================] - 172s 721ms/step - loss: 0.0227 - acc: 0.0500 - val_loss: 0.0179 - val_acc: 0.0510
Epoch 9/10
238/238 [==============================] - 176s 740ms/step - loss: 0.0221 - acc: 0.0500 - val_loss: 0.0174 - val_acc: 0.0510
Epoch 10/10
238/238 [==============================] - 169s 711ms/step - loss: 0.0210 - acc: 0.0500 - val_loss: 0.0175 - val_acc: 0.0510
Epoch 00010: early stopping


Shadow augmentation:

2019-04-13 19:52:21.427594: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.1 locally
372/372 [==============================] - 194s 521ms/step - loss: 0.1606 - acc: 0.0444 - val_loss: 0.0304 - val_acc: 0.0516
Epoch 2/10
372/372 [==============================] - 200s 539ms/step - loss: 0.0426 - acc: 0.0537 - val_loss: 0.0226 - val_acc: 0.0517
Epoch 3/10
372/372 [==============================] - 208s 558ms/step - loss: 0.0314 - acc: 0.0539 - val_loss: 0.0207 - val_acc: 0.0517
Epoch 4/10
372/372 [==============================] - 210s 565ms/step - loss: 0.0264 - acc: 0.0540 - val_loss: 0.0198 - val_acc: 0.0517
Epoch 5/10
372/372 [==============================] - 212s 569ms/step - loss: 0.0233 - acc: 0.0541 - val_loss: 0.0192 - val_acc: 0.0517
Epoch 6/10
372/372 [==============================] - 208s 559ms/step - loss: 0.0216 - acc: 0.0541 - val_loss: 0.0166 - val_acc: 0.0517
Epoch 7/10
372/372 [==============================] - 211s 568ms/step - loss: 0.0200 - acc: 0.0539 - val_loss: 0.0162 - val_acc: 0.0517
Epoch 8/10
372/372 [==============================] - 212s 570ms/step - loss: 0.0192 - acc: 0.0539 - val_loss: 0.0166 - val_acc: 0.0517
Epoch 00008: early stopping

3x Schattendurchfahrt große Auflösung, batch norm raus, LR auf 0.001 angepasst

397/397 [==============================] - 196s 493ms/step - loss: 0.0335 - acc: 0.0543 - val_loss: 0.0213 - val_acc: 0.0477
Epoch 2/10
397/397 [==============================] - 199s 502ms/step - loss: 0.0212 - acc: 0.0545 - val_loss: 0.0179 - val_acc: 0.0477
Epoch 3/10
397/397 [==============================] - 198s 500ms/step - loss: 0.0188 - acc: 0.0545 - val_loss: 0.0166 - val_acc: 0.0477
Epoch 4/10
397/397 [==============================] - 202s 509ms/step - loss: 0.0176 - acc: 0.0545 - val_loss: 0.0148 - val_acc: 0.0477
Epoch 5/10
397/397 [==============================] - 204s 514ms/step - loss: 0.0166 - acc: 0.0545 - val_loss: 0.0140 - val_acc: 0.0477
Epoch 6/10
397/397 [==============================] - 195s 491ms/step - loss: 0.0162 - acc: 0.0545 - val_loss: 0.0138 - val_acc: 0.0477
Epoch 7/10
397/397 [==============================] - 197s 495ms/step - loss: 0.0155 - acc: 0.0545 - val_loss: 0.0137 - val_acc: 0.0477
Epoch 8/10
397/397 [==============================] - 200s 504ms/step - loss: 0.0150 - acc: 0.0545 - val_loss: 0.0131 - val_acc: 0.0477
Epoch 9/10
397/397 [==============================] - 200s 503ms/step - loss: 0.0145 - acc: 0.0545 - val_loss: 0.0134 - val_acc: 0.0477
Epoch 00009: early stopping

OO approach
Epoch 1/10
2019-04-14 11:18:51.876930: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-04-14 11:18:51.911002: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2594085000 Hz
2019-04-14 11:18:51.911744: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55f1d10023a0 executing computations on platform Host. Devices:
2019-04-14 11:18:51.911795: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-04-14 11:18:51.979386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-04-14 11:18:51.980435: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55f1d0ef2de0 executing computations on platform CUDA. Devices:
2019-04-14 11:18:51.980466: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 950M, Compute Capability 5.0
2019-04-14 11:18:51.980867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: GeForce GTX 950M major: 5 minor: 0 memoryClockRate(GHz): 1.124
pciBusID: 0000:01:00.0
totalMemory: 1.96GiB freeMemory: 1.92GiB
2019-04-14 11:18:51.981056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-04-14 11:18:52.727954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-14 11:18:52.728004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-04-14 11:18:52.728023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-04-14 11:18:52.728363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1666 MB memory) -> physical GPU (device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2019-04-14 11:18:53.511140: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.1 locally
397/397 [==============================] - 188s 473ms/step - loss: 0.0348 - val_loss: 0.0257
Epoch 2/10
397/397 [==============================] - 181s 457ms/step - loss: 0.0265 - val_loss: 0.0238
Epoch 3/10
397/397 [==============================] - 179s 450ms/step - loss: 0.0242 - val_loss: 0.0209
Epoch 4/10
397/397 [==============================] - 178s 449ms/step - loss: 0.0223 - val_loss: 0.0198
Epoch 5/10
397/397 [==============================] - 178s 448ms/step - loss: 0.0205 - val_loss: 0.0174
Epoch 6/10
397/397 [==============================] - 177s 447ms/step - loss: 0.0197 - val_loss: 0.0169
Epoch 7/10
397/397 [==============================] - 177s 447ms/step - loss: 0.0179 - val_loss: 0.0150
Epoch 8/10
397/397 [==============================] - 176s 444ms/step - loss: 0.0170 - val_loss: 0.0142
Epoch 9/10
397/397 [==============================] - 178s 449ms/step - loss: 0.0156 - val_loss: 0.0124
Epoch 10/10
397/397 [==============================] - 178s 448ms/step - loss: 0.0145 - val_loss: 0.0121
